{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SudokuDenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SvEVq1OvK4v-GtrjBrNxqaL5polIZzBe",
      "authorship_tag": "ABX9TyN+Cxmr0gLLq5KV5D1Tq9SM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrealtinok/sudoku_solvers/blob/main/SudokuDenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gh9WM7EyOZF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AqenVpDHEy"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_9EXQYVDPLx"
      },
      "source": [
        "# Imports 3 million sudoku puzzles and their solutions\n",
        "\n",
        "sudoku_3mil = 'drive/My Drive/sudoku3m.csv'\n",
        "puzzles = np.zeros((3000000, 81), np.int32)\n",
        "solutions = np.zeros((3000000, 81), np.int32)\n",
        "\n",
        "for i, line in enumerate(open(sudoku_3mil, 'r').read().splitlines()):\n",
        "    puzzle, solution = line.split(',')\n",
        "    for j, p_s in enumerate(zip(puzzle, solution)):\n",
        "        p, s = p_s\n",
        "        puzzles[i, j] = p\n",
        "        solutions[i, j] = s\n",
        "puzzles = puzzles.reshape((-1, 9, 9))\n",
        "solutions = solutions.reshape((-1, 9, 9))\n",
        "\n",
        "X = puzzles\n",
        "X = np.expand_dims(X, axis=-1) \n",
        "Y = solutions\n",
        "Y = np.expand_dims(Y, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8QLy3-cDRCq",
        "outputId": "5997ad25-4b76-4a51-e70b-0b7de8d0d451"
      },
      "source": [
        "# Sets the initializer, the callbacks and the optimizer\n",
        "\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, \n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('drive/My Drive/sudoku_densenet_model',\n",
        "                                                      save_best_only=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
        "\n",
        "\n",
        "# Defines a function that combines Batch Normalization and ReLU activation\n",
        "\n",
        "def batchnorm_relu(x):\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)  \n",
        "  return x\n",
        "\n",
        "# Defines a function that forms densely connected convolution blocks\n",
        "\n",
        "def densenet_block(x, d=None):\n",
        "\n",
        "  if d is None:\n",
        "    dense = x\n",
        "  else:\n",
        "    dense = d\n",
        "\n",
        "  conv1 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(x)\n",
        "  conv1 = tf.keras.layers.Conv2D(81, (3, 3), padding='same', kernel_initializer=initializer)(conv1)\n",
        "  conv1 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(conv1)\n",
        "  con1 = tf.keras.layers.Concatenate()([dense, conv1])\n",
        "  act1 = batchnorm_relu(con1)\n",
        "\n",
        "  conv2 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(act1)\n",
        "  conv2 = tf.keras.layers.Conv2D(81, (1, 9), padding='same', kernel_initializer=initializer)(conv2)\n",
        "  conv2 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(conv2)\n",
        "  con2 = tf.keras.layers.Concatenate()([con1, conv2])\n",
        "  act2 = batchnorm_relu(con2)\n",
        "  \n",
        "  conv3 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(act2)\n",
        "  conv3 = tf.keras.layers.Conv2D(81, (9, 1), padding='same', kernel_initializer=initializer)(conv3)\n",
        "  conv3 = tf.keras.layers.Conv2D(10, (1, 1), padding='same', kernel_initializer=initializer)(conv3)\n",
        "  con3 = tf.keras.layers.Concatenate()([con2, conv3])\n",
        "  act3 = batchnorm_relu(con3)\n",
        "  \n",
        "  return act3, con3\n",
        "\n",
        "# Defines the input, the layers and the output of the model\n",
        "\n",
        "input = tf.keras.Input((9, 9, 1))\n",
        "\n",
        "act_con, dense_con = densenet_block(input)\n",
        "for i in range(80):\n",
        "  act_con, dense_con = densenet_block(act_con, dense_con)\n",
        "\n",
        "output = tf.keras.layers.Conv2D(10, (1, 1), activation='softmax')(act_con)\n",
        "\n",
        "# Initiates the model\n",
        "\n",
        "model = tf.keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "# Compiles the model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "# Trains the model\n",
        "\n",
        "model.fit(X, Y,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          callbacks=[early_stopping, model_checkpoint],\n",
        "          validation_split=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "46407/46407 [==============================] - ETA: 0s - loss: 0.4023 - sparse_categorical_accuracy: 0.8260WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/sudoku_densenet_model/assets\n",
            "46407/46407 [==============================] - 14772s 318ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.3267 - val_sparse_categorical_accuracy: 0.8652\n",
            "Epoch 2/100\n",
            "46407/46407 [==============================] - ETA: 0s - loss: 0.2791 - sparse_categorical_accuracy: 0.8831INFO:tensorflow:Assets written to: drive/My Drive/sudoku_densenet_model/assets\n",
            "46407/46407 [==============================] - 14797s 319ms/step - loss: 0.2791 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.2674 - val_sparse_categorical_accuracy: 0.8896\n",
            "Epoch 3/100\n",
            "46407/46407 [==============================] - ETA: 0s - loss: 0.2443 - sparse_categorical_accuracy: 0.8990INFO:tensorflow:Assets written to: drive/My Drive/sudoku_densenet_model/assets\n",
            "46407/46407 [==============================] - 14798s 319ms/step - loss: 0.2443 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9003\n",
            "Epoch 4/100\n",
            "46407/46407 [==============================] - ETA: 0s - loss: 0.2250 - sparse_categorical_accuracy: 0.9075INFO:tensorflow:Assets written to: drive/My Drive/sudoku_densenet_model/assets\n",
            "46407/46407 [==============================] - 14811s 319ms/step - loss: 0.2250 - sparse_categorical_accuracy: 0.9075 - val_loss: 0.2273 - val_sparse_categorical_accuracy: 0.9086\n",
            "Epoch 5/100\n",
            "14023/46407 [========>.....................] - ETA: 2:49:50 - loss: 0.2148 - sparse_categorical_accuracy: 0.9120"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUXmzeY2kYv"
      },
      "source": [
        "# Loads the trained model\n",
        "\n",
        "loaded_model = tf.keras.models.load_model('drive/My Drive/sudoku_densenet_model_cont')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udTzE2i7aWCu",
        "outputId": "be6890bd-8b5f-4827-a60f-68045d944cc9"
      },
      "source": [
        "# Continues training the model\n",
        "\n",
        "# Sets the initializer, the callbacks and the optimizer\n",
        "\n",
        "model_checkpoint_cont = tf.keras.callbacks.ModelCheckpoint('drive/My Drive/sudoku_densenet_model_cont',\n",
        "                                                      save_best_only=True)\n",
        "early_stopping_cont = tf.keras.callbacks.EarlyStopping(patience=2, \n",
        "                                                  restore_best_weights=True)\n",
        "optimizer_cont = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.1)\n",
        "\n",
        "# Compiles the model\n",
        "\n",
        "loaded_model.compile(\n",
        "    optimizer=optimizer_cont,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "# Trains the model\n",
        "\n",
        "loaded_model.fit(X, Y,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          callbacks=[early_stopping_cont, model_checkpoint_cont],\n",
        "          validation_split=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "46407/46407 [==============================] - 22098s 475ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9320 - val_loss: 0.1713 - val_sparse_categorical_accuracy: 0.9298\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/sudoku_densenet_model_cont/assets\n",
            "Epoch 2/100\n",
            " 7118/46407 [===>..........................] - ETA: 5:10:16 - loss: 0.1652 - sparse_categorical_accuracy: 0.9325Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8XZ0gCs2Liv"
      },
      "source": [
        "# Imports 1000 Sudoku puzzles and their solutions\n",
        "\n",
        "sudoku_1000 = 'drive/My Drive/1000Sudokus - Sheet1.csv'\n",
        "puzzles_test = np.zeros((1000, 81), np.int32)\n",
        "solutions_test = np.zeros((1000, 81), np.int32)\n",
        "for i, line in enumerate(open(sudoku_1000, 'r').read().splitlines()):\n",
        "    puzzle, solution = line.split(\",\")\n",
        "    for j, q_s in enumerate(zip(puzzle, solution)):\n",
        "        q, s = q_s\n",
        "        puzzles_test[i, j] = q\n",
        "        solutions_test[i, j] = s\n",
        "puzzles_test = puzzles_test.reshape((-1, 9, 9))\n",
        "solutions_test = solutions_test.reshape((-1, 9, 9))\n",
        "\n",
        "X_test = puzzles_test\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "Y_test = solutions_test\n",
        "Y_test = np.expand_dims(Y_test, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnahhW4m2ySh",
        "outputId": "9d2179cb-35d9-46c4-dfdc-8477bd9be511"
      },
      "source": [
        "# Evaluates model (sparse_categorical_accuracy: 0.9402)\n",
        "\n",
        "loaded_model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 16s 141ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1475314497947693, 0.9401851892471313]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl_IBbdJKQl5",
        "outputId": "f82d9095-23a8-4273-b1ab-859f37ef7f24"
      },
      "source": [
        "# Solves 1000 Sudoku puzzles through step-by-step inference (907/1000)\n",
        "\n",
        "for j in range(2):  \n",
        "  count = 0\n",
        "  for i in range(1000):\n",
        "    X_temp = X_test[i]\n",
        "    X_temp = np.expand_dims(X_temp, axis=0)\n",
        "    while np.count_nonzero(X_temp) < 81:\n",
        "      pred = loaded_model.predict(X_temp)\n",
        "      prediction = np.argmax(pred, axis=-1)\n",
        "      prediction_prob = np.amax(pred, axis=-1)\n",
        "      k, l = 0, 0\n",
        "      prob = 0\n",
        "      for i in range(9):\n",
        "        for j in range(9):\n",
        "          if X_temp[0, i, j, 0] == 0:\n",
        "            if prediction_prob[0, i, j] > prob:\n",
        "              prob = prediction_prob[0, i, j]\n",
        "              k, l = i, j\n",
        "      X_temp[0, k, l, 0] = prediction[0, k, l]\n",
        "    comparison = X_temp.reshape(1, 9, 9) == Y_test[i].reshape(1, 9, 9)\n",
        "    if comparison.all():\n",
        "      count += 1\n",
        "  print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "907\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}